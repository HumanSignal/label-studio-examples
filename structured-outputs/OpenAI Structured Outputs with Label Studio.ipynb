{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Structured Outputs with Label Studio\n",
    "This notebook demonstrates how to use OpenAI’s Structured Outputs feature with Label Studio for various labeling tasks such as summarization, text classification, and named entity recognition (NER). By defining schemas with Pydantic, we can directly generate JSON outputs that integrate seamlessly with Label Studio, reducing the need for preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "Install necessary packages, and initialize the OpenAI client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install openai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List, Union, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Import and initialize the OpenAI client\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Studio Summarization\n",
    "Summarization is the process of condensing a larger body of text into a shorter version while preserving its essential information and meaning. We will use OpenAI’s API to generate concise summaries from longer texts. This can be useful for extracting key points from articles, reports, or any extensive document.\n",
    "\n",
    "First, we define a schema for summarization using Pydantic to ensure the output matches Label Studio’s requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label(BaseModel):\n",
    "    score: float\n",
    "    text: str\n",
    "\n",
    "\n",
    "class ResultItem(BaseModel):\n",
    "    id: str\n",
    "    from_name: Literal[\"answer\"] = \"answer\"\n",
    "    to_name: Literal[\"text\"] = \"text\"\n",
    "    type: Literal[\"textarea\"] = \"textarea\"\n",
    "    value: Label\n",
    "\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    model_version: str\n",
    "    result: List[ResultItem]\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "class Summarization(BaseModel):\n",
    "    data: Data\n",
    "    predictions: List[Prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the text we want to summarize. In this case, we will use a paragraph from Wikipedia on the 2024 Olympics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_input = \"The 2024 Summer Olympics,[a] officially the Games of the XXXIII Olympiad[b] and branded as Paris 2024, were an international multi-sport event that occurred from 26 July to 11 August 2024 in France, with the opening ceremony having taken place on 26 July. Paris was the host city, with events (mainly football) held in 16 additional cities spread across metropolitan France, including the sailing centre in the second-largest city of France, Marseille on the Mediterranean Sea, as well as one subsite for surfing in Tahiti, French Polynesia.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request a summarization completion with the defined schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a Summarization assistant.\n",
    "                Your job is to identify and a best, single sentence summary \n",
    "                for a given piece of text. Ensure that there is only a single \n",
    "                summary for the given text.\"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": summary_input\n",
    "        }\n",
    "    ],\n",
    "    response_format=Summarization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"text\": \"The 2024 Summer Olympics, officially known as the Games of the XXXIII Olympiad, took place in Paris, France from 26 July to 11 August 2024, with additional events held in various cities across metropolitan France and one surfing site in Tahiti.\"\n",
      "    },\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"model_version\": \"legacy\",\n",
      "            \"result\": [\n",
      "                {\n",
      "                    \"id\": \"summary1\",\n",
      "                    \"from_name\": \"answer\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"textarea\",\n",
      "                    \"value\": {\n",
      "                        \"score\": 1.0,\n",
      "                        \"text\": \"The 2024 Summer Olympics, officially known as the Games of the XXXIII Olympiad, took place in Paris, France from 26 July to 11 August 2024, with additional events held in various cities across metropolitan France and one surfing site in Tahiti.\"\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(summarization_completion.choices[0].message.content), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the output as a file, which can then be imported into our Label Studio project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to file\n",
    "summary_filename = 'summary_prediction.json'\n",
    "\n",
    "# Write JSON object to a file\n",
    "with open(summary_filename, 'w') as file:\n",
    "    json.dump(json.loads(summarization_completion.choices[0].message.content), file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Studio Text Classification \n",
    "Classification involves categorizing text into predefined classes or labels based on its content. In this case, we will use Sentiment Analysis for the classification task. |\n",
    "\n",
    "Once again, we will create our pydantic schema for the json structure that we want the LLM to populate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityType(str, Enum):\n",
    "    positive = \"Positive\"\n",
    "    negative = \"Negative\"\n",
    "    neutral = \"Neutral\"\n",
    "\n",
    "class Label(BaseModel):\n",
    "    score: float\n",
    "    choices: List[EntityType]\n",
    "\n",
    "class ResultItem(BaseModel):\n",
    "    id: str\n",
    "    from_name: Literal[\"sentiment\"] = \"sentiment\"\n",
    "    to_name: Literal[\"text\"] = \"text\"\n",
    "    type: Literal[\"choices\"] = \"choices\"\n",
    "    value: Label\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    model_version: str\n",
    "    result: List[ResultItem]\n",
    "\n",
    "class Data(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    data: Data\n",
    "    predictions: List[Prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the text that we want to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_input = \"We’re excited to announce the 1.13 release of Label Studio! This update includes a refreshed UI and some new Generative AI templates for you to use.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a Sentiment analysis assistant.\n",
    "                Your job is to provide the sentiment for  \n",
    "                for a given piece of text. Ensure that there is only a single \n",
    "                sentiment for the given text.\"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": classification_input\n",
    "        }\n",
    "    ],\n",
    "    response_format=Classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"text\": \"We\\u2019re excited to announce the 1.13 release of Label Studio! This update includes a refreshed UI and some new Generative AI templates for you to use.\"\n",
      "    },\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"model_version\": \"1.0\",\n",
      "            \"result\": [\n",
      "                {\n",
      "                    \"id\": \"1\",\n",
      "                    \"from_name\": \"sentiment\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"choices\",\n",
      "                    \"value\": {\n",
      "                        \"score\": 0.98,\n",
      "                        \"choices\": [\n",
      "                            \"Positive\"\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(classification_completion.choices[0].message.content), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save the output as a file, which can then be imported into our Label Studio project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to file\n",
    "classification_filename = 'classification_prediction.json'\n",
    "\n",
    "# Write JSON object to a file\n",
    "with open(classification_filename, 'w') as file:\n",
    "    json.dump(json.loads(classification_completion.choices[0].message.content), file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Studio NER Example\n",
    "Named Entity Recognition (NER) is a natural language processing task that identifies and classifies key entities in text, such as names of people, organizations, locations, dates, and other specific terms. This task is more complex because it not only requires recognizing entity names but also accurately determining their positions within the text, including the exact character offsets (start and end positions). While Large Language Models (LLMs) are capable of identifying these entities, they often struggle with providing precise offsets, which can lead to inconsistencies in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityType(str, Enum):\n",
    "    person = \"Person\"\n",
    "    organization = \"Organization\"\n",
    "    location = \"Location\"\n",
    "    datetime = \"DateTime\"\n",
    "    product = \"Product\"\n",
    "    percent = \"Percent\"\n",
    "    fact = \"Fact\"\n",
    "    money = \"Money\"\n",
    "\n",
    "\n",
    "class Label(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "    score: float\n",
    "    text: str\n",
    "    labels: List[EntityType]\n",
    "\n",
    "\n",
    "class ResultItem(BaseModel):\n",
    "    id: str\n",
    "    from_name: Literal[\"label\"] = \"label\"\n",
    "    to_name: Literal[\"text\"] = \"text\"\n",
    "    type: Literal[\"labels\"] = \"labels\"\n",
    "    value: Label\n",
    "\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    model_version: str\n",
    "    # score: Optional[float] = None\n",
    "    result: List[ResultItem]\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "class NamedEntities(BaseModel):\n",
    "    data: Data\n",
    "    predictions: List[Prediction]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_input = \"Samuel Harris Altman (born April 22, 1985) is an American entrepreneur and investor best known as the CEO of OpenAI since 2019 (he was briefly fired and reinstated in November 2023).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a Named Entity Recognition (NER) assistant.\n",
    "                Your job is to identify and return all entity names and their \n",
    "                types for a given piece of text. You are to strictly conform\n",
    "                only to the following entity types: Person, Location, Organization\n",
    "                and DateTime. If uncertain about entity type, please ignore it.\n",
    "                Be careful of certain acronyms, such as role titles \"CEO\", \"CTO\",\n",
    "                \"VP\", etc - these are to be ignore.\"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": ner_input\n",
    "        }\n",
    "    ],\n",
    "    response_format=NamedEntities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"text\": \"Samuel Harris Altman (born April 22, 1985) is an American entrepreneur and investor best known as the CEO of OpenAI since 2019 (he was briefly fired and reinstated in November 2023).\"\n",
      "    },\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"model_version\": \"1.0\",\n",
      "            \"result\": [\n",
      "                {\n",
      "                    \"id\": \"1\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 0,\n",
      "                        \"end\": 18,\n",
      "                        \"score\": 0.95,\n",
      "                        \"text\": \"Samuel Harris Altman\",\n",
      "                        \"labels\": [\n",
      "                            \"Person\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"2\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 25,\n",
      "                        \"end\": 39,\n",
      "                        \"score\": 0.9,\n",
      "                        \"text\": \"April 22, 1985\",\n",
      "                        \"labels\": [\n",
      "                            \"DateTime\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"3\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 136,\n",
      "                        \"end\": 142,\n",
      "                        \"score\": 0.92,\n",
      "                        \"text\": \"OpenAI\",\n",
      "                        \"labels\": [\n",
      "                            \"Organization\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"4\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 171,\n",
      "                        \"end\": 184,\n",
      "                        \"score\": 0.88,\n",
      "                        \"text\": \"November 2023\",\n",
      "                        \"labels\": [\n",
      "                            \"DateTime\"\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(ner_completion.choices[0].message.content), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we review the data in Label Studio, we can see that the LLM identified the named entities, but it did not generate the character offsets correctly. We can fix this with a simple regex before saving the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"text\": \"Samuel Harris Altman (born April 22, 1985) is an American entrepreneur and investor best known as the CEO of OpenAI since 2019 (he was briefly fired and reinstated in November 2023).\"\n",
      "    },\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"model_version\": \"1.0\",\n",
      "            \"result\": [\n",
      "                {\n",
      "                    \"id\": \"1\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 0,\n",
      "                        \"end\": 20,\n",
      "                        \"score\": 0.95,\n",
      "                        \"text\": \"Samuel Harris Altman\",\n",
      "                        \"labels\": [\n",
      "                            \"Person\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"2\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 27,\n",
      "                        \"end\": 41,\n",
      "                        \"score\": 0.9,\n",
      "                        \"text\": \"April 22, 1985\",\n",
      "                        \"labels\": [\n",
      "                            \"DateTime\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"3\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 109,\n",
      "                        \"end\": 115,\n",
      "                        \"score\": 0.92,\n",
      "                        \"text\": \"OpenAI\",\n",
      "                        \"labels\": [\n",
      "                            \"Organization\"\n",
      "                        ]\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"4\",\n",
      "                    \"from_name\": \"label\",\n",
      "                    \"to_name\": \"text\",\n",
      "                    \"type\": \"labels\",\n",
      "                    \"value\": {\n",
      "                        \"start\": 167,\n",
      "                        \"end\": 180,\n",
      "                        \"score\": 0.88,\n",
      "                        \"text\": \"November 2023\",\n",
      "                        \"labels\": [\n",
      "                            \"DateTime\"\n",
      "                        ]\n",
      "                    }\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "json_data = json.loads(ner_completion.choices[0].message.content)\n",
    "\n",
    "# Extract the text to search in\n",
    "text = json_data[\"data\"][\"text\"]\n",
    "\n",
    "# Iterate over each result in predictions to update start and end indexes\n",
    "for prediction in json_data[\"predictions\"]:\n",
    "    for result in prediction[\"result\"]:\n",
    "        # Get the text to find in the main text\n",
    "        search_text = result[\"value\"][\"text\"]\n",
    "        \n",
    "        # Use regex to find the exact position of the search_text in text\n",
    "        match = re.search(re.escape(search_text), text)\n",
    "        if match:\n",
    "            # Update start and end indexes with exact positions\n",
    "            result[\"value\"][\"start\"] = match.start()\n",
    "            result[\"value\"][\"end\"] = match.end()\n",
    "\n",
    "# Print the updated JSON\n",
    "print(json.dumps(json_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our corrected NER prediction, we can save it and import it into Label Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'formatted_ner_prediction.json'\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
